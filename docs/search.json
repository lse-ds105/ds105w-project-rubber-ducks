[
  {
    "objectID": "progress_presentation.html#data-pipeline-diagram",
    "href": "progress_presentation.html#data-pipeline-diagram",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Data Pipeline Diagram",
    "text": "Data Pipeline Diagram\n\n\n\n\n\nflowchart LR\n    A{open-meteo} --&gt; L((open-meteo API Requests))\n    L --&gt; B[London Dataframe]\n    L --&gt; C[Bangkok Dataframe]\n    L --&gt; D[ ... ]\n    L --&gt; E[Hong Kong Dataframe]\n    G{top 20 cities website} --&gt;|scraping| H(python list of 20 cities)\n    I{OpenStreetMaps} --&gt; J((OSM API request))\n    H --&gt; J\n    J --&gt; K(python list of dictionaries for coordinates of all cities)\n    K --&gt; L\n    B --&gt; M[Weather Dataframe:&lt;br&gt;each row is a time and city]\n    C --&gt; M\n    D --&gt; M\n    E --&gt; M\n    M -.- F(save as .csv files)\n    N{Google NGRAMS} --&gt; S(json format)\n    S --&gt;|scraping| T[dataframe of appearance % for each query]\n    T --&gt; |sum by years| U[NGRAMS Dataframe]\n    U -.- F\n    M --&gt; V[Final SQL Database]\n    U --&gt; V\n    V --&gt;|Data manipulation| O(London Visualisations)\n    V --&gt;|Data manipulation| Q(Descriptive Visualisations)\n    V --&gt;|Data manipulation| R(More Complex and Interactive Visualisations)"
  },
  {
    "objectID": "progress_presentation.html#scraping-the-20-most-visited-cities",
    "href": "progress_presentation.html#scraping-the-20-most-visited-cities",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Scraping the 20 most visited cities",
    "text": "Scraping the 20 most visited cities\nimport requests\nfrom scrapy import Selector\ncities_url = \"https://travelness.com/most-visited-cities-in-the-world\" # URL of the page with the list of cities\n\nresponse = requests.get(cities_url)\nsel = Selector(response)\n\ncities = sel.xpath(\"//table//tr/td[2]/text()\").getall()\nThis returns a list of the top 20 most visited cities:\n['Bangkok', 'Paris', 'London', 'Dubai', 'Singapore', 'Kuala Lumpur', 'New York', 'Istanbul', 'Tokyo', 'Antalya', 'Seoul', 'Osaka', 'Makkah', 'Phuket', 'Pattaya', 'Milan', 'Barcelona', 'Palma de Mallorca', 'Bali', 'Hong Kong SAR']"
  },
  {
    "objectID": "progress_presentation.html#geocoding-the-cities",
    "href": "progress_presentation.html#geocoding-the-cities",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Geocoding the cities",
    "text": "Geocoding the cities\nThe open-meteo API requires that we input coordinates and so we first had to take the city names and geocode them using the OpenStreetMaps API.\nfrom geopy.geocoders import Nominatim\n\ndef geocode_city(city):\n    geolocator = Nominatim(user_agent=\"my_geocoder\")\n    location = geolocator.geocode(city)\n    return {\"city\": city, \"latitude\": location.latitude, \"longitude\": location.longitude}\n\ndef geocode_cities(city_list):\n    geocoded_cities = [geocode_city(city) for city in city_list if geocode_city(city)]\n    return geocoded_cities\n\n# Geocode the list of cities\ngeocoded_cities = geocode_cities(cities)"
  },
  {
    "objectID": "progress_presentation.html#geocoding-the-cities-1",
    "href": "progress_presentation.html#geocoding-the-cities-1",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Geocoding the cities",
    "text": "Geocoding the cities\nThis returns a list of dictionaries, here is one of the items as an example:\n{\"city\": \"Paris\", \"latitude\": 48.8534951, \"longitude\": 2.3483915}"
  },
  {
    "objectID": "progress_presentation.html#preparing-the-open-meteo-api-call",
    "href": "progress_presentation.html#preparing-the-open-meteo-api-call",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Preparing the open-meteo API call",
    "text": "Preparing the open-meteo API call\nThe open-meteo API takes in a dictionary of parameters.\nparams = {\n    \"latitude\": [city[\"latitude\"] for city in geocoded_cities],\n    \"longitude\": [city[\"longitude\"] for city in geocoded_cities],\n    \"start_date\": \"1940-01-01\",\n    \"end_date\": \"2023-12-31\",\n    \"daily\": daily_variables_of_interest,\n}"
  },
  {
    "objectID": "progress_presentation.html#the-actual-api-call",
    "href": "progress_presentation.html#the-actual-api-call",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "The actual API call",
    "text": "The actual API call\nHere we use the code provided in the open-meteo API documentation to get a list of responses for each city.\n# Setup the Open-Meteo API client with cache and retry on error\ncache_session = requests_cache.CachedSession('.cache', expire_after = -1)\nretry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\nopenmeteo = openmeteo_requests.Client(session = retry_session)\n\nurl = \"https://archive-api.open-meteo.com/v1/archive\"\nresponses = openmeteo.weather_api(url, params=params)"
  },
  {
    "objectID": "progress_presentation.html#transforming-the-data-into-our-desired-format",
    "href": "progress_presentation.html#transforming-the-data-into-our-desired-format",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Transforming the data into our desired format",
    "text": "Transforming the data into our desired format\nOnce we retrieved our API responses, we had to manipulate them into a useable format as the actual API response is just a list of responses that look like this:\n&lt;openmeteo_sdk.WeatherApiResponse.WeatherApiResponse at 0x7fd78b1f7d30&gt;\nThis is obviously not very usefulâ€¦"
  },
  {
    "objectID": "progress_presentation.html#open-meteo-api-documentation-and-example-code",
    "href": "progress_presentation.html#open-meteo-api-documentation-and-example-code",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Open-meteo API documentation and example code",
    "text": "Open-meteo API documentation and example code\nThe open-meteo API does provide you with useable code for returning pandas dataframes for each city, but their code was not desirable for a few reasons:\n\nReturned a list of dataframes for each city.\nEach dataframe had no way of distinguishing it from the other dataframes meaning that if we merged them then we wouldnâ€™t know which datapoints correspond to which cities."
  },
  {
    "objectID": "progress_presentation.html#how-did-we-overcome-this",
    "href": "progress_presentation.html#how-did-we-overcome-this",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "How did we overcome this?",
    "text": "How did we overcome this?\nUsing the documentation, we wrote a function that processes each response and adds the city name.\nimport pandas as pd\nimport openmeteo_requests\n\ndef process_response(response, geocoded_cities, i):\n    daily = response.Daily()\n    temperature_2m_max = daily.Variables(0).ValuesAsNumpy()\n    temperature_2m_min = daily.Variables(1).ValuesAsNumpy()\n    temperature_2m_mean = daily.Variables(2).ValuesAsNumpy()\n    daylight_duration = daily.Variables(3).ValuesAsNumpy()\n    sunshine_duration = daily.Variables(4).ValuesAsNumpy()\n    precipitation_sum = daily.Variables(5).ValuesAsNumpy()\n    rain_sum = daily.Variables(6).ValuesAsNumpy()\n    precipitation_hours = daily.Variables(7).ValuesAsNumpy()\n\n    daily_data = {\n        \"date\": pd.date_range(\n            start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n            end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n            freq=pd.Timedelta(seconds=daily.Interval()),\n            inclusive=\"left\"\n        ).date\n    }\n\n    daily_data[\"city\"] = geocoded_cities[i]['city']\n    daily_data[\"temperature_2m_max\"] = temperature_2m_max\n    daily_data[\"temperature_2m_min\"] = temperature_2m_min\n    daily_data[\"temperature_2m_mean\"] = temperature_2m_mean\n    daily_data[\"daylight_duration\"] = daylight_duration\n    daily_data[\"sunshine_duration\"] = sunshine_duration\n    daily_data[\"precipitation_sum\"] = precipitation_sum\n    daily_data[\"rain_sum\"] = rain_sum\n    daily_data[\"precipitation_hours\"] = precipitation_hours\n\n    return pd.DataFrame(data=daily_data)"
  },
  {
    "objectID": "progress_presentation.html#how-did-we-overcome-this-1",
    "href": "progress_presentation.html#how-did-we-overcome-this-1",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "How did we overcome this?",
    "text": "How did we overcome this?\nNow we can merge the dataframes.\ndataframes_list = [cf.process_response(response, geocoded_cities, i) for i, response in enumerate(responses)]\nmerged_df = pd.concat(dataframes_list, ignore_index=True)\nmerged_df.to_csv(\"../data/weather_data.csv\", index=False)"
  },
  {
    "objectID": "progress_presentation.html#final-outcome",
    "href": "progress_presentation.html#final-outcome",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Final Outcome",
    "text": "Final Outcome\nDataframe with over 600,000 rows.\n\n\n\n\n\n\n\n\ndate\n\n\ncity\n\n\ntemperature_2m_max\n\n\ntemperature_2m_min\n\n\ntemperature_2m_mean\n\n\ndaylight_duration\n\n\nsunshine_duration\n\n\nprecipitation_sum\n\n\nrain_sum\n\n\nprecipitation_hours\n\n\n\n\n\n\n0\n\n\n1940-01-01\n\n\nBangkok\n\n\n27.061001\n\n\n14.711\n\n\n20.571415\n\n\n40775.191406\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n0.0\n\n\n\n\n1\n\n\n1940-01-02\n\n\nBangkok\n\n\n26.961000\n\n\n14.111\n\n\n20.248503\n\n\n40786.789062\n\n\n38087.828125\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n2\n\n\n1940-01-03\n\n\nBangkok\n\n\n26.261000\n\n\n13.911\n\n\n19.719332\n\n\n40799.343750\n\n\n38101.910156\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n3\n\n\n1940-01-04\n\n\nBangkok\n\n\n27.961000\n\n\n14.161\n\n\n20.523499\n\n\n40812.839844\n\n\n38117.046875\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n4\n\n\n1940-01-05\n\n\nBangkok\n\n\n28.661001\n\n\n14.211\n\n\n21.300581\n\n\n40827.265625\n\n\n38133.210938\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n5\n\n\n1940-01-06\n\n\nBangkok\n\n\n29.911001\n\n\n15.361\n\n\n22.540167\n\n\n40842.601562\n\n\n38150.390625\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n6\n\n\n1940-01-07\n\n\nBangkok\n\n\n30.261000\n\n\n15.461\n\n\n22.473501\n\n\n40858.835938\n\n\n38168.574219\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n7\n\n\n1940-01-08\n\n\nBangkok\n\n\n30.961000\n\n\n16.961\n\n\n23.983917\n\n\n40875.949219\n\n\n38187.718750\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n8\n\n\n1940-01-09\n\n\nBangkok\n\n\n30.961000\n\n\n17.511\n\n\n24.306831\n\n\n40893.960938\n\n\n38207.929688\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n9\n\n\n1940-01-10\n\n\nBangkok\n\n\n30.561001\n\n\n19.361\n\n\n24.577669\n\n\n40913.089844\n\n\n37394.550781\n\n\n0.0\n\n\n0.0\n\n\n0.0"
  },
  {
    "objectID": "progress_presentation.html#final-outcome-1",
    "href": "progress_presentation.html#final-outcome-1",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Final Outcome",
    "text": "Final Outcome\nmerged_df[merged_df['city']=='London'].describe()\nSummary statistics for London data:\n\n\n\n\n\n\n\n\ntemperature_2m_max\n\n\ntemperature_2m_min\n\n\ntemperature_2m_mean\n\n\ndaylight_duration\n\n\nsunshine_duration\n\n\nprecipitation_sum\n\n\nrain_sum\n\n\nprecipitation_hours\n\n\n\n\n\n\ncount\n\n\n30681.000000\n\n\n30681.000000\n\n\n30681.000000\n\n\n30681.000000\n\n\n30680.000000\n\n\n30680.000000\n\n\n30680.000000\n\n\n30681.000000\n\n\n\n\nmean\n\n\n13.774742\n\n\n6.729281\n\n\n10.306868\n\n\n44177.980469\n\n\n25653.326172\n\n\n1.691261\n\n\n1.642960\n\n\n3.851146\n\n\n\n\nstd\n\n\n6.194537\n\n\n5.271986\n\n\n5.609030\n\n\n10799.614258\n\n\n16077.271484\n\n\n3.265338\n\n\n3.221255\n\n\n5.007728\n\n\n\n\nmin\n\n\n-6.454500\n\n\n-15.904500\n\n\n-8.721166\n\n\n28170.857422\n\n\n0.000000\n\n\n0.000000\n\n\n0.000000\n\n\n0.000000\n\n\n\n\n25%\n\n\n9.195499\n\n\n2.795500\n\n\n6.139249\n\n\n33813.128906\n\n\n12710.077148\n\n\n0.000000\n\n\n0.000000\n\n\n0.000000\n\n\n\n\n50%\n\n\n13.745500\n\n\n6.995500\n\n\n10.437167\n\n\n44288.531250\n\n\n25880.933594\n\n\n0.200000\n\n\n0.200000\n\n\n1.000000\n\n\n\n\n75%\n\n\n18.545500\n\n\n10.945499\n\n\n14.853833\n\n\n54571.656250\n\n\n38797.984375\n\n\n1.900000\n\n\n1.800000\n\n\n7.000000\n\n\n\n\nmax\n\n\n37.952000\n\n\n20.851999\n\n\n29.131165\n\n\n59899.007812\n\n\n55052.890625\n\n\n39.900002\n\n\n39.900002\n\n\n24.000000"
  },
  {
    "objectID": "progress_presentation.html#google-ngrams",
    "href": "progress_presentation.html#google-ngrams",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Google NGRAMS",
    "text": "Google NGRAMS\nAdding to our analysis the perception of London as a rainy city through literature Scraping method:\n\nTransformed the Google NGRAM graphs into json format.\nCreate a dataframe for each query and merge them.\nFor analysis purposes, we summed the frequencies to give a general idea of the perception per year."
  },
  {
    "objectID": "progress_presentation.html#google-ngrams-1",
    "href": "progress_presentation.html#google-ngrams-1",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Google NGRAMS",
    "text": "Google NGRAMS\n\n\n\n\nYear\nAppearence %\n\n\n\n\n0\n1940\n2.731485e-09\n\n\n1\n1941\n2.756745e-09\n\n\n2\n1942\n2.743879e-09\n\n\n3\n1943\n2.774656e-09\n\n\n4\n1944\n2.788329e-09"
  },
  {
    "objectID": "progress_presentation.html#next-steps",
    "href": "progress_presentation.html#next-steps",
    "title": "Rubber Ducks ðŸ¦† weather analysis project",
    "section": "Next steps",
    "text": "Next steps\n\nStore the data as a database.\nAdjust the datatypes of each column to be most appropriate and efficient because 6,000,000 pieces of data is a lot."
  }
]